{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dcc21a-5489-47d5-94ae-c53cf6d1dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62c0653-2ff9-48a7-8d7a-560cf2f708d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test function defined!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def friedman_test(data):\n",
    "    \"\"\"\n",
    "    Compute Friedman test statistic.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy array of shape (n_datasets, n_algorithms)\n",
    "        Performance scores for each algorithm on each dataset (fold)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    chi2_f : float\n",
    "        Friedman test statistic\n",
    "    p_value : float\n",
    "        P-value\n",
    "    avg_ranks : numpy array\n",
    "        Average ranks for each algorithm\n",
    "    \"\"\"\n",
    "    n_datasets, k = data.shape\n",
    "    \n",
    "    # Rank algorithms for each dataset (lower is better for time, higher for performance)\n",
    "    ranks = np.zeros_like(data)\n",
    "    for i in range(n_datasets):\n",
    "        # For training time: lower is better (rank 1 = fastest)\n",
    "        # For accuracy/F-measure: higher is better (rank 1 = best)\n",
    "        ranks[i] = stats.rankdata(-data[i])  # Negative for descending order\n",
    "    \n",
    "    # Average ranks across datasets\n",
    "    avg_ranks = np.mean(ranks, axis=0)\n",
    "    \n",
    "    # Friedman statistic\n",
    "    rank_sum_sq = np.sum(avg_ranks ** 2)\n",
    "    chi2_f = (12 * n_datasets / (k * (k + 1))) * (rank_sum_sq - k * ((k + 1) ** 2) / 4)\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df = k - 1\n",
    "    \n",
    "    # P-value from chi-square distribution\n",
    "    p_value = 1 - stats.chi2.cdf(chi2_f, df)\n",
    "    \n",
    "    return chi2_f, p_value, avg_ranks\n",
    "\n",
    "print(\"Friedman test function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6da4cde-c33f-4c04-93db-d5a02613543a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nemenyi test function defined!\n"
     ]
    }
   ],
   "source": [
    "def nemenyi_critical_difference(n_datasets, k, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate critical difference for Nemenyi post-hoc test.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_datasets : int\n",
    "        Number of datasets (folds)\n",
    "    k : int\n",
    "        Number of algorithms\n",
    "    alpha : float\n",
    "        Significance level (default 0.05)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    cd : float\n",
    "        Critical difference\n",
    "    \"\"\"\n",
    "    # Critical values for Nemenyi test (studentized range statistic)\n",
    "    # For alpha=0.05\n",
    "    q_alpha_values = {\n",
    "        2: 1.960, 3: 2.343, 4: 2.569, 5: 2.728, 6: 2.850,\n",
    "        7: 2.949, 8: 3.031, 9: 3.102, 10: 3.164\n",
    "    }\n",
    "    \n",
    "    if k not in q_alpha_values:\n",
    "        raise ValueError(f\"Number of algorithms {k} not supported. Use 2-10 algorithms.\")\n",
    "    \n",
    "    q_alpha = q_alpha_values[k]\n",
    "    \n",
    "    # Critical difference formula\n",
    "    cd = q_alpha * np.sqrt((k * (k + 1)) / (6 * n_datasets))\n",
    "    \n",
    "    return cd\n",
    "\n",
    "print(\"Nemenyi test function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b79939a-c848-42fb-a593-283065df0850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading function defined!\n"
     ]
    }
   ],
   "source": [
    "def load_spambase_data(filepath='spambase.data'):\n",
    "    \"\"\"\n",
    "    Load and preprocess the Spambase dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to the spambase.data file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy array\n",
    "        Feature matrix\n",
    "    y : numpy array\n",
    "        Target labels\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(filepath, header=None)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "print(\"Data loading function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cea38e-4759-44c2-8d11-3df6853a0783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset loaded successfully!\n",
      "  - Number of samples: 4601\n",
      "  - Number of features: 57\n",
      "  - Class distribution: [2788 1813]\n",
      "    * Non-spam (0): 2788\n",
      "    * Spam (1): 1813\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    X, y = load_spambase_data('spambase.data')\n",
    "    print(f\"âœ“ Dataset loaded successfully!\")\n",
    "    print(f\"  - Number of samples: {X.shape[0]}\")\n",
    "    print(f\"  - Number of features: {X.shape[1]}\")\n",
    "    print(f\"  - Class distribution: {np.bincount(y.astype(int))}\")\n",
    "    print(f\"    * Non-spam (0): {np.sum(y == 0)}\")\n",
    "    print(f\"    * Spam (1): {np.sum(y == 1)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âœ— ERROR: spambase.data not found!\")\n",
    "    print(\"  Please download from: https://archive.ics.uci.edu/ml/datasets/Spambase\")\n",
    "    print(\"  and place it in the same directory as this notebook.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0547f84b-a6e7-4a51-9bc9-9fbe034fed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_algorithms(X, y, n_folds=10):\n",
    "    \"\"\"\n",
    "    Evaluate three algorithms using stratified 10-fold cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy array\n",
    "        Feature matrix\n",
    "    y : numpy array\n",
    "        Target labels\n",
    "    n_folds : int\n",
    "        Number of folds for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing results for each metric and algorithm\n",
    "    \"\"\"\n",
    "    # Initialize algorithms\n",
    "    algorithms = {\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'SVM': SVC(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Initialize result storage\n",
    "    results = {\n",
    "        'training_time': {name: [] for name in algorithms.keys()},\n",
    "        'accuracy': {name: [] for name in algorithms.keys()},\n",
    "        'f_measure': {name: [] for name in algorithms.keys()}\n",
    "    }\n",
    "    \n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_num = 1\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        print(f\"Processing Fold {fold_num}/{n_folds}...\", end=' ')\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Evaluate each algorithm\n",
    "        for name, clf in algorithms.items():\n",
    "            # Measure training time\n",
    "            start_time = time.time()\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = clf.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='binary')\n",
    "            \n",
    "            # Store results\n",
    "            results['training_time'][name].append(training_time)\n",
    "            results['accuracy'][name].append(acc)\n",
    "            results['f_measure'][name].append(f1)\n",
    "        \n",
    "        print(\"âœ“\")\n",
    "        fold_num += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Evaluation function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "241cdb56-a5e4-421d-8fed-0dd591b6faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RUNNING 10-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RUNNING 10-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b0d0b5-c8f5-4f0c-8160-68f7a2da2bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1/10... âœ“\n",
      "Processing Fold 2/10... âœ“\n",
      "Processing Fold 3/10... âœ“\n",
      "Processing Fold 4/10... âœ“\n",
      "Processing Fold 5/10... âœ“\n",
      "Processing Fold 6/10... âœ“\n",
      "Processing Fold 7/10... âœ“\n",
      "Processing Fold 8/10... âœ“\n",
      "Processing Fold 9/10... âœ“\n",
      "Processing Fold 10/10... âœ“\n",
      "\n",
      "âœ“ All experiments completed successfully!\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_algorithms(X, y)\n",
    "\n",
    "print()\n",
    "print(\"âœ“ All experiments completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375c6b42-cf54-4a88-baff-79206d4458ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(results, metric_name):\n",
    "    \"\"\"\n",
    "    Create results table similar to Example 12.4 format.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "    df.index = [f'Fold {i+1}' for i in range(len(df))]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76fa6e1e-c4d7-4e91-8c58-e70fae90c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_friedman_results(chi2_f, p_value, avg_ranks, algorithm_names, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Display Friedman test results in Example 12.8 format.\n",
    "    \"\"\"\n",
    "    print(f\"\\nFriedman Test Results:\")\n",
    "    print(f\"  Friedman Statistic (Ï‡Â²_F): {chi2_f:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.6f}\")\n",
    "    print(f\"\\nAverage Ranks:\")\n",
    "    for name, rank in zip(algorithm_names, avg_ranks):\n",
    "        print(f\"  {name}: {rank:.2f}\")\n",
    "    \n",
    "    # Determine significance\n",
    "    is_significant = p_value < alpha\n",
    "    \n",
    "    print(f\"\\nSignificance Test (Î± = {alpha}):\")\n",
    "    if is_significant:\n",
    "        print(f\"  Result: SIGNIFICANT (p-value = {p_value:.6f} < {alpha})\")\n",
    "        print(f\"  Conclusion: Average ranks display significant differences.\")\n",
    "    else:\n",
    "        print(f\"  Result: NOT SIGNIFICANT (p-value = {p_value:.6f} â‰¥ {alpha})\")\n",
    "        print(f\"  Conclusion: No significant differences between average ranks.\")\n",
    "    \n",
    "    return is_significant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7932fee-b7ec-4abb-b032-12362b0581e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display functions defined!\n"
     ]
    }
   ],
   "source": [
    "def display_nemenyi_results(avg_ranks, algorithm_names, cd):\n",
    "    \"\"\"\n",
    "    Display Nemenyi post-hoc test results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nNemenyi Post-hoc Test:\")\n",
    "    print(f\"  Critical Difference (CD): {cd:.4f}\")\n",
    "    print(f\"\\n  Pairwise Comparisons:\")\n",
    "    \n",
    "    for i in range(len(algorithm_names)):\n",
    "        for j in range(i+1, len(algorithm_names)):\n",
    "            rank_diff = abs(avg_ranks[i] - avg_ranks[j])\n",
    "            is_diff = rank_diff > cd\n",
    "            status = \"SIGNIFICANTLY DIFFERENT\" if is_diff else \"Not significantly different\"\n",
    "            symbol = \">\" if is_diff else \"â‰¤\"\n",
    "            print(f\"    {algorithm_names[i]} vs {algorithm_names[j]}:\")\n",
    "            print(f\"      |{avg_ranks[i]:.2f} - {avg_ranks[j]:.2f}| = {rank_diff:.4f} {symbol} {cd:.4f}\")\n",
    "            print(f\"      â†’ {status}\")\n",
    "\n",
    "print(\"Display functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34a99d9f-9164-405e-b40e-017e66eaceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METRIC 1: TRAINING TIME (seconds)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"METRIC 1: TRAINING TIME (seconds)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0be6984-8628-4b2e-be39-2df2edb683da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Table (Example 12.4 format):\n",
      "         Decision Tree  Naive Bayes       SVM\n",
      "Fold 1        0.230827     0.011002  0.599080\n",
      "Fold 2        0.188874     0.008985  0.660902\n",
      "Fold 3        0.195478     0.007761  0.637772\n",
      "Fold 4        0.172305     0.012038  0.625663\n",
      "Fold 5        0.216024     0.011557  0.642468\n",
      "Fold 6        0.186496     0.015835  0.609977\n",
      "Fold 7        0.155667     0.000000  0.634517\n",
      "Fold 8        0.184652     0.007031  0.663057\n",
      "Fold 9        0.184547     0.008024  0.628366\n",
      "Fold 10       0.219564     0.012486  0.628730\n"
     ]
    }
   ],
   "source": [
    "# Create results table\n",
    "metric = 'training_time'\n",
    "results_df = create_results_table(results[metric], metric)\n",
    "\n",
    "print(\"\\nResults Table (Example 12.4 format):\")\n",
    "print(results_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c1b578-da92-498e-955d-31efb584e609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Friedman Test Results:\n",
      "  Friedman Statistic (Ï‡Â²_F): 20.0000\n",
      "  P-value: 0.000045\n",
      "\n",
      "Average Ranks:\n",
      "  Decision Tree: 2.00\n",
      "  Naive Bayes: 1.00\n",
      "  SVM: 3.00\n",
      "\n",
      "Significance Test (Î± = 0.05):\n",
      "  Result: SIGNIFICANT (p-value = 0.000045 < 0.05)\n",
      "  Conclusion: Average ranks display significant differences.\n",
      "\n",
      "Nemenyi Post-hoc Test:\n",
      "  Critical Difference (CD): 1.0478\n",
      "\n",
      "  Pairwise Comparisons:\n",
      "    Decision Tree vs Naive Bayes:\n",
      "      |2.00 - 1.00| = 1.0000 â‰¤ 1.0478\n",
      "      â†’ Not significantly different\n",
      "    Decision Tree vs SVM:\n",
      "      |2.00 - 3.00| = 1.0000 â‰¤ 1.0478\n",
      "      â†’ Not significantly different\n",
      "    Naive Bayes vs SVM:\n",
      "      |1.00 - 3.00| = 2.0000 > 1.0478\n",
      "      â†’ SIGNIFICANTLY DIFFERENT\n",
      "\n",
      "Results saved to: results_training_time.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array for statistical tests\n",
    "data_array = results_df.values\n",
    "\n",
    "# For training time: lower is better, so negate for ranking\n",
    "rank_data = -data_array\n",
    "\n",
    "# Friedman test\n",
    "algorithm_names = list(results[metric].keys())\n",
    "chi2_f, p_value, avg_ranks = friedman_test(rank_data)\n",
    "\n",
    "is_significant = display_friedman_results(chi2_f, p_value, avg_ranks, algorithm_names)\n",
    "\n",
    "# Nemenyi test if significant\n",
    "if is_significant:\n",
    "    n_datasets = data_array.shape[0]\n",
    "    k = data_array.shape[1]\n",
    "    cd = nemenyi_critical_difference(n_datasets, k, alpha=0.05)\n",
    "    display_nemenyi_results(avg_ranks, algorithm_names, cd)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('results_training_time.csv')\n",
    "print(f\"\\nResults saved to: results_training_time.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46bd851a-fe83-4331-b215-3ec510156c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Friedman Test Results:\n",
      "  Friedman Statistic (Ï‡Â²_F): 20.0000\n",
      "  P-value: 0.000045\n",
      "\n",
      "Average Ranks:\n",
      "  Decision Tree: 2.00\n",
      "  Naive Bayes: 3.00\n",
      "  SVM: 1.00\n",
      "\n",
      "Significance Test (Î± = 0.05):\n",
      "  Result: SIGNIFICANT (p-value = 0.000045 < 0.05)\n",
      "  Conclusion: Average ranks display significant differences.\n"
     ]
    }
   ],
   "source": [
    "#Convert to numpy array for statistical tests\n",
    "data_array = results_df.values\n",
    "\n",
    "# For accuracy: higher is better\n",
    "rank_data = data_array\n",
    "\n",
    "# Friedman test\n",
    "algorithm_names = list(results[metric].keys())\n",
    "chi2_f, p_value, avg_ranks = friedman_test(rank_data)\n",
    "\n",
    "is_significant = display_friedman_results(chi2_f, p_value, avg_ranks, algorithm_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bbbab2c-620c-4df8-8238-e2f4d5baab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nemenyi Post-hoc Test:\n",
      "  Critical Difference (CD): 1.0478\n",
      "\n",
      "  Pairwise Comparisons:\n",
      "    Decision Tree vs Naive Bayes:\n",
      "      |2.00 - 3.00| = 1.0000 â‰¤ 1.0478\n",
      "      â†’ Not significantly different\n",
      "    Decision Tree vs SVM:\n",
      "      |2.00 - 1.00| = 1.0000 â‰¤ 1.0478\n",
      "      â†’ Not significantly different\n",
      "    Naive Bayes vs SVM:\n",
      "      |3.00 - 1.00| = 2.0000 > 1.0478\n",
      "      â†’ SIGNIFICANTLY DIFFERENT\n",
      "\n",
      "Results saved to: results_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "# Nemenyi test if significant\n",
    "if is_significant:\n",
    "    n_datasets = data_array.shape[0]\n",
    "    k = data_array.shape[1]\n",
    "    cd = nemenyi_critical_difference(n_datasets, k, alpha=0.05)\n",
    "    display_nemenyi_results(avg_ranks, algorithm_names, cd)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('results_accuracy.csv')\n",
    "print(f\"\\nResults saved to: results_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b30202-439a-4079-ae68-77913da5da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METRIC 3: F-MEASURE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"=\"*80)\n",
    "print(\"METRIC 3: F-MEASURE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c14ed48-47a3-404e-9926-aebeb50a44fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Table (Example 12.4 format):\n",
      "         Decision Tree  Naive Bayes       SVM\n",
      "Fold 1        0.852632     0.807512  0.896359\n",
      "Fold 2        0.878873     0.806527  0.910112\n",
      "Fold 3        0.901099     0.787330  0.922222\n",
      "Fold 4        0.931507     0.801843  0.904494\n",
      "Fold 5        0.882979     0.804598  0.919220\n",
      "Fold 6        0.879781     0.781038  0.932584\n",
      "Fold 7        0.889503     0.816229  0.903955\n",
      "Fold 8        0.898072     0.806683  0.918310\n",
      "Fold 9        0.901639     0.827423  0.928367\n",
      "Fold 10       0.868132     0.801843  0.914773\n"
     ]
    }
   ],
   "source": [
    "# Create results table\n",
    "metric = 'f_measure'\n",
    "results_df = create_results_table(results[metric], metric)\n",
    "\n",
    "print(\"\\nResults Table (Example 12.4 format):\")\n",
    "print(results_df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21d0d8e5-a374-4ab4-8261-e7fdf37af08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Friedman Test Results:\n",
      "  Friedman Statistic (Ï‡Â²_F): 18.2000\n",
      "  P-value: 0.000112\n",
      "\n",
      "Average Ranks:\n",
      "  Decision Tree: 1.90\n",
      "  Naive Bayes: 3.00\n",
      "  SVM: 1.10\n",
      "\n",
      "Significance Test (Î± = 0.05):\n",
      "  Result: SIGNIFICANT (p-value = 0.000112 < 0.05)\n",
      "  Conclusion: Average ranks display significant differences.\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array for statistical tests\n",
    "data_array = results_df.values\n",
    "\n",
    "# For F-measure: higher is better\n",
    "rank_data = data_array\n",
    "\n",
    "# Friedman test\n",
    "algorithm_names = list(results[metric].keys())\n",
    "chi2_f, p_value, avg_ranks = friedman_test(rank_data)\n",
    "\n",
    "is_significant = display_friedman_results(chi2_f, p_value, avg_ranks, algorithm_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b54c643e-9000-4254-ba19-755cc8e4a591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nemenyi Post-hoc Test:\n",
      "  Critical Difference (CD): 1.0478\n",
      "\n",
      "  Pairwise Comparisons:\n",
      "    Decision Tree vs Naive Bayes:\n",
      "      |1.90 - 3.00| = 1.1000 > 1.0478\n",
      "      â†’ SIGNIFICANTLY DIFFERENT\n",
      "    Decision Tree vs SVM:\n",
      "      |1.90 - 1.10| = 0.8000 â‰¤ 1.0478\n",
      "      â†’ Not significantly different\n",
      "    Naive Bayes vs SVM:\n",
      "      |3.00 - 1.10| = 1.9000 > 1.0478\n",
      "      â†’ SIGNIFICANTLY DIFFERENT\n",
      "\n",
      "ðŸ’¾ Results saved to: results_f_measure.csv\n"
     ]
    }
   ],
   "source": [
    "# Nemenyi test if significant\n",
    "if is_significant:\n",
    "    n_datasets = data_array.shape[0]\n",
    "    k = data_array.shape[1]\n",
    "    cd = nemenyi_critical_difference(n_datasets, k, alpha=0.05)\n",
    "    display_nemenyi_results(avg_ranks, algorithm_names, cd)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('results_f_measure.csv')\n",
    "print(f\"\\nðŸ’¾ Results saved to: results_f_measure.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf0bc481-e53c-4a9b-8656-d105d5c4333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE SUMMARY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE SUMMARY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a93db040-e73c-459f-a22c-0c8da8e41478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean performance for each metric and algorithm\n",
    "summary_data = []\n",
    "\n",
    "for metric in ['training_time', 'accuracy', 'f_measure']:\n",
    "    for alg_name in results[metric].keys():\n",
    "        mean_val = np.mean(results[metric][alg_name])\n",
    "        std_val = np.std(results[metric][alg_name])\n",
    "        summary_data.append({\n",
    "            'Metric': metric.replace('_', ' ').title(),\n",
    "            'Algorithm': alg_name,\n",
    "            'Mean': mean_val,\n",
    "            'Std Dev': std_val\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e85a1d9-36a5-41e2-80a6-1f22c750c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Mean Performance Summary:\n",
      "       Metric     Algorithm     Mean  Std Dev\n",
      "Training Time Decision Tree 0.193443 0.021664\n",
      "Training Time   Naive Bayes 0.009472 0.004047\n",
      "Training Time           SVM 0.633053 0.018897\n",
      "     Accuracy Decision Tree 0.911113 0.017052\n",
      "     Accuracy   Naive Bayes 0.816560 0.014765\n",
      "     Accuracy           SVM 0.934365 0.008434\n",
      "    F Measure Decision Tree 0.888422 0.020431\n",
      "    F Measure   Naive Bayes 0.804103 0.012405\n",
      "    F Measure           SVM 0.915040 0.010829\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“ˆ Mean Performance Summary:\")\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e65b50c5-9ff8-423c-883e-6d220be187ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ“ ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Generated files:\n",
      "  - results_training_time.csv\n",
      "  - results_accuracy.csv\n",
      "  - results_f_measure.csv\n",
      "\n",
      "Use these results to complete your IEEE conference report!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - results_training_time.csv\")\n",
    "print(\"  - results_accuracy.csv\")\n",
    "print(\"  - results_f_measure.csv\")\n",
    "print(\"\\nUse these results to complete your IEEE conference report!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3ac9532-e92d-4b30-84ce-3e0416a52738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "metrics = ['training_time', 'accuracy', 'f_measure']\n",
    "titles = ['Training Time (seconds)', 'Accuracy', 'F-measure']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aee59312-d5d4-49fa-a991-d7c1146b7cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Visualization saved as: performance_comparison.png\n"
     ]
    }
   ],

